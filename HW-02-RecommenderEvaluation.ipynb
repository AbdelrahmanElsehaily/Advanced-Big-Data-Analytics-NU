{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "from random import randrange,choices\n",
    "\n",
    "conf = SparkConf().set(\"spark.driver.memory\", \"6g\")\n",
    "sc = SparkContext.getOrCreate(conf=conf) #new in Spark 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title(s):\n",
    "    print(\"---- %s -----\" %s)    \n",
    "    \n",
    "def see(s, v):\n",
    "    print(\"---- %s -----\" %s)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the AreaUnderCurve function\n",
    "## Requirements:\n",
    "You are required to build the function that calculates the area under the curve (AUC). This function is used to measure the quality of the recommneder model. The idea is to simply measure the probability that a randomly chosen good (we know the user played) recommendation ranks above a randomly chosen bad (we know the user didnt' play) recommendation.\n",
    "\n",
    "AUC accepts the CV dataset as the “positive” or “good” artists for each user, and a prediction function. This function translates each user-artist pair into a prediction as a Rating containing the user, artist, and a number wherein higher values mean higher rank in the recommendations.\n",
    "\n",
    "\n",
    "Fill all the code under lines like this:\n",
    "\n",
    "<font color=\"red\">### ---CODE HERE --- ###</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "#### `isInt`\n",
    "- Checks if a string is an integer\n",
    "\n",
    "#### `buildArtistAlias`\n",
    "- Map artist alias ID to a unique artist ID\n",
    "- Handle corrupt non-convertable to int ids by ignoring them\n",
    "\n",
    "####  `buildRatings`\n",
    "`Rating(user, product, rating)`\n",
    "- Represents a (user, product, rating) tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isInt(s):\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def buildArtistAlias(rawArtistAlias):\n",
    "    # Convert ther rawArtistData into tuples of (aliasID, artistID)\n",
    "    # Filter all bad lines\n",
    "    return rawArtistAlias \\\n",
    "        .map(lambda line: line.split('\\t')) \\\n",
    "        .filter(lambda artist: artist[0] and isInt(artist[0])) \\\n",
    "        .map(lambda artist: (int(artist[0]), int(artist[1]))) \\\n",
    "        .collectAsMap()\n",
    "\n",
    "        \n",
    "def getArtistRating(line):\n",
    "    # Parse the line to extract the 3 fields\n",
    "    (userID, artistID, count) = map(lambda x: int(x), line.split(' '))\n",
    "    try:\n",
    "        # Lookup if the current artistID is an just an alias to an artist\n",
    "        # The lookup is done from a the broadcast RDD\n",
    "        finalArtistID = bArtistAlias.value[artistID]\n",
    "    except KeyError:\n",
    "        # if the lookup failed, then we have a new artist\n",
    "        finalArtistID = artistID\n",
    "    #Finally, create a new rating Object\n",
    "    return Rating(userID, finalArtistID, count)\n",
    "\n",
    "\n",
    "# Go over all User-Artist data and convert each line to a Rating object\n",
    "def buildRatings(rawUserArtistData, bArtistAlias):\n",
    "    return rawUserArtistData.map(lambda line: getArtistRating(line))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and caching the files RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1214361"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --Replace the base location with your local path--\n",
    "base = \"../data/profiledata_06-May-2005/\"\n",
    "rawArtistAlias = sc.textFile(base + \"artist_alias.txt\").cache()\n",
    "rawUserArtistData = sc.textFile(base + \"user_artist_data.txt\").cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting sample of the data because of the out of memory issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawUserArtistData=rawUserArtistData.sample(fraction=0.05,seed=17,withReplacement=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the artist aliases and user ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artistAlias = buildArtistAlias(rawArtistAlias)\n",
    "bArtistAlias = sc.broadcast(artistAlias)\n",
    "\n",
    "allData = buildRatings(rawUserArtistData, bArtistAlias)\n",
    "allItemIDs = allData.map(lambda item: item.product).distinct().collect()\n",
    "bAllItemIDs = sc.broadcast(allItemIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allData.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into trainData (90%) and cvData (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainData, cvData) = allData.randomSplit(weights=[0.9, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ALS.trainImplicit(ratings=trainData, rank=10, iterations=5, lambda_=0.01, alpha=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the `areaUnderCurve` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def areaUnderCurve(positiveData, bAllItemIDs, predictFunction):\n",
    "    \n",
    "    \n",
    "    ### ---CODE HERE (2 vars below)--- ###\n",
    "    # positiveData contains information about artists who were listend to by certain users.\n",
    "    # Create a positiveUserProducts that maps the positiveDate to (userID, artistID) tuple.\n",
    "    positiveUserProducts = positiveData.map(lambda row:(row.user,row.product))\n",
    "    \n",
    "    # We need to create a negativeUserProducts that contains artists the user did not listen to.\n",
    "    ## - Group the artists of each user in a (userID1, [artistID1, artistID12,.....]) tuple.\n",
    "    groupedPositiveUserProducts = positiveUserProducts.groupByKey()\n",
    "    \n",
    "    ## - For each user, map their artist list to a new randomly selected unseed list of artists \n",
    "    ## - To do this, you need to implement a pos2neg function that takes the user and list of positive artists as parameters \n",
    "    ### - Selects a random artists from all artists (hint: bAllItemIDs)\n",
    "    ### - Checks if the selected random artists is not in the positive artisits list\n",
    "    ### - If not then add it to a negative list\n",
    "    ### - Stop when the negative artists list is as big as the positive artists list.\n",
    "    ### - return a tuple that contains that userID and the new negative artists list\n",
    "    def pos2neg(userID,positiveArtists):\n",
    "        ### ---CODE HERE--- ###\n",
    "        filter_list=[x for x in bAllItemIDs.value if x not in positiveArtists ]\n",
    "        negativeArtisits=choices(population=filter_list,k=len(positiveArtists),cum_weights=None,)\n",
    "        return (userID, negativeArtisits)\n",
    "\n",
    "    \n",
    "    \n",
    "    ### ---CODE HERE (5 vars below)--- ###\n",
    "    groupedNegativeUserProducts = groupedPositiveUserProducts.map(lambda x:pos2neg(x[0],x[1]))\n",
    "\n",
    "    # - Map (userID1, [artistID1, artistID12,.....]) tuple to [(userID1, artistID1), (user1, artistID2), ...]\n",
    "    negativeUserProducts =groupedNegativeUserProducts.flatMapValues(lambda x:x)\n",
    "\n",
    "    # Use the predictFunction with positiveUserProducts and negativeUserProductsto get\n",
    "    # the rating value for each user, artist tuple and group each by the user\n",
    "    positivePredictions = predictFunction(positiveUserProducts).map(lambda row: (row.user,row.rating)).groupByKey()\n",
    "    negativePredictions = predictFunction(negativeUserProducts).map(lambda row: (row.user,row.rating)).groupByKey()\n",
    "    \n",
    "    # Join the predicted output of the positive and negative RDD and get their value only (drop the key)\n",
    "    posAndNegRatingsJoined = positivePredictions.join(negativePredictions).map(lambda x: x[1])\n",
    "    print (posAndNegRatingsJoined.take(5))\n",
    "    # Map the joined RDD to calcualte the probability of true positive\n",
    "    ## To do this, you need to create a function probabilityOfTruePositive \n",
    "        #that takes the postive and negative artists ratings list of a user as a parameter\n",
    "    ### - For each positive artist, count the number of times the positive rating was higher than the negative rating\n",
    "    ### - Divid the count produced from the previous step with the total count of items in the positive and negative lists  \n",
    "    ### - return the final ouptut\n",
    "    def probabilityOfTruePositive(positiveRatings, negativeRatings):\n",
    "        ### ---CODE HERE--- ###\n",
    "        total=len(positiveRatings)**2\n",
    "        correct=0\n",
    "        for good in positiveRatings:\n",
    "            correct+=len([x for x in negativeRatings if x<good])\n",
    "        return float(correct)/total\n",
    "    \n",
    "    ### ---CODE HERE (2 vars below)--- ###\n",
    "    probabilities =posAndNegRatingsJoined.map(lambda rating: probabilityOfTruePositive(list(rating[0]),list(rating[1])))\n",
    "    mean = sum(probabilities.collect())/probabilities.count()\n",
    "    \n",
    "    # Return the mean of the RDD producted above.\n",
    "    return mean\n",
    "\n",
    "\n",
    "areaUnderCurve(cvData, bAllItemIDs, model.predictAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output:\n",
    "~*0.9659*"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
