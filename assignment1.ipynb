{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "#Used for features and labels in any supervised learning\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "#Used for storing a set of features in the LabeledPoint\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "#Used to compute model performance metrics\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "#Used to build the decisionTree model\n",
    "from pyspark.mllib.tree import DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title(s):\n",
    "    print(\"---- %s -----\" %s)    \n",
    "    \n",
    "def see(s, v):\n",
    "    print(\"---- %s -----\" %s)\n",
    "    print(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate() #new in Spark 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data=sc.textFile(\"../assignment-data/HR_comma_sep.csv\")\n",
    "raw_data.count()\n",
    "analysisRDD=raw_data.filter(lambda line: not(line.startswith(\"satisfaction\"))).map(lambda line:line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- row data -----\n",
      "['satisfaction_level,last_evaluation,number_project,average_montly_hours,time_spend_company,Work_accident,left,promotion_last_5years,sales,salary', '0.38,0.53,2,157,3,0,1,0,sales,low', '0.8,0.86,5,262,6,0,1,0,sales,medium']\n",
      "----  before encoding analysisRDD -----\n",
      "[['0.38', '0.53', '2', '157', '3', '0', '1', '0', 'sales', 'low'], ['0.8', '0.86', '5', '262', '6', '0', '1', '0', 'sales', 'medium']]\n"
     ]
    }
   ],
   "source": [
    "see(\"row data\",raw_data.take(3))\n",
    "see(\" before encoding analysisRDD\",analysisRDD.take(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['hr',\n",
       "  'technical',\n",
       "  'support',\n",
       "  'management',\n",
       "  'sales',\n",
       "  'accounting',\n",
       "  'IT',\n",
       "  'product_mng',\n",
       "  'marketing',\n",
       "  'RandD'],\n",
       " ['low', 'medium', 'high'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the classes of the required to encode features\n",
    "depclasses=analysisRDD.map(lambda x:(x[8],0)).distinct().keys().collect()\n",
    "salaryclasses=analysisRDD.map(lambda x:(x[9],0)).distinct().keys().collect()\n",
    "depclasses,salaryclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(row):\n",
    "    #getting the department and salary then removing them from the list\n",
    "    dep=row[8]\n",
    "    salary=row[9]\n",
    "    del row[8:10]\n",
    "    label =row[6]\n",
    "    del row[6]\n",
    "#     encoding the data\n",
    "    for i in depclasses:\n",
    "        row.append(1) if i==dep else row.append(0)\n",
    "    for i in salaryclasses:\n",
    "        row.append(1) if i==salary else row.append(0)\n",
    "#     row.append(depclasses.index(dep))\n",
    "#     row.append(salaryclasses.index(salary))\n",
    "\n",
    "    featureVector = Vectors.dense(row)\n",
    "    return LabeledPoint(label, featureVector)\n",
    "encodedRDD=analysisRDD.map(preprocessing)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [0.38,0.53,2.0,157.0,3.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(1.0, [0.8,0.86,5.0,262.0,6.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0]),\n",
       " LabeledPoint(1.0, [0.11,0.88,7.0,272.0,4.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0]),\n",
       " LabeledPoint(1.0, [0.72,0.87,5.0,223.0,5.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(1.0, [0.37,0.52,2.0,159.0,3.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[684] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trainData, cvData, testData) = encodedRDD.randomSplit(weights=[0.8, 0.1, 0.1],seed=17)\n",
    "trainData.cache()\n",
    "cvData.cache()\n",
    "testData.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 ms, sys: 8 ms, total: 28 ms\n",
      "Wall time: 985 ms\n"
     ]
    }
   ],
   "source": [
    "def buildDecisionTreeClassifier(trainData):\n",
    "    model = DecisionTree.trainClassifier(trainData,numClasses=2, categoricalFeaturesInfo={}, impurity=\"gini\", maxDepth=3, maxBins=100)\n",
    "    return  model\n",
    "%time m1 =  buildDecisionTreeClassifier(trainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcuating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 717 ms\n",
      "---- accuracy -----\n",
      "0.9546632124352331\n"
     ]
    }
   ],
   "source": [
    "def getMetrics(model, data):\n",
    "    labels = data.map(lambda d: d.label)\n",
    "    features = data.map(lambda d: d.features)\n",
    "    predictions = model.predict(features)\n",
    "    predictionsAndLabels = predictions.zip(labels)\n",
    "    return MulticlassMetrics(predictionsAndLabels)\n",
    "metrics = getMetrics(m1, cvData)\n",
    "%time accuracy = metrics.accuracy\n",
    "see(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('gini', 1, 10), 0.7875647668393783),\n",
       " (('gini', 1, 300), 0.8134715025906736),\n",
       " (('gini', 20, 10), 0.9656735751295337),\n",
       " (('gini', 20, 300), 0.977979274611399),\n",
       " (('entropy', 1, 10), 0.7875647668393783),\n",
       " (('entropy', 1, 300), 0.8134715025906736),\n",
       " (('entropy', 20, 10), 0.9682642487046632),\n",
       " (('entropy', 20, 300), 0.9766839378238342)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(trainData, cvData):\n",
    "    evaluations = []\n",
    "    #Take combinations of 3 hyperparams, evaluation the accuracy of each using CV Dataset\n",
    "    for impurity in [\"gini\", \"entropy\"]:\n",
    "        for depth in [1, 20]:\n",
    "            for bins in [10, 300]:\n",
    "                model = DecisionTree.trainClassifier(trainData,numClasses=7, categoricalFeaturesInfo={}, impurity=impurity, maxDepth=depth, maxBins=bins)\n",
    "                accuracy = getMetrics(model, cvData).accuracy\n",
    "                evaluations.append(((impurity, depth, bins), accuracy))\n",
    "\n",
    "    return evaluations\n",
    "evaluations = evaluate(trainData, cvData)\n",
    "evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Sorted Evaluations -----\n",
      "(('gini', 20, 300), 0.977979274611399)\n",
      "(('entropy', 20, 300), 0.9766839378238342)\n",
      "(('entropy', 20, 10), 0.9682642487046632)\n",
      "(('gini', 20, 10), 0.9656735751295337)\n",
      "(('gini', 1, 300), 0.8134715025906736)\n",
      "(('entropy', 1, 300), 0.8134715025906736)\n",
      "(('gini', 1, 10), 0.7875647668393783)\n",
      "(('entropy', 1, 10), 0.7875647668393783)\n"
     ]
    }
   ],
   "source": [
    "sortedEvals = sorted(evaluations, key=lambda a:a[1], reverse=True)\n",
    "title(\"Sorted Evaluations\")\n",
    "for e in sortedEvals:\n",
    "    print(e)\n",
    "bestParams = sortedEvals[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- testData accuracy -----\n",
      "0.9813019390581718\n",
      "---- testData+cvData accuracy -----\n",
      "0.9909638554216867\n"
     ]
    }
   ],
   "source": [
    "(i, d, b) = bestParams\n",
    "model = DecisionTree.trainClassifier(\n",
    "    trainData.union(cvData),\n",
    "    numClasses=7, \n",
    "    categoricalFeaturesInfo={}, \n",
    "    impurity=i, \n",
    "    maxDepth=d, \n",
    "    maxBins=b)\n",
    "see(\"testData accuracy\",getMetrics(model, testData).accuracy)\n",
    "see(\"testData+cvData accuracy\", getMetrics(model, testData.union(cvData)).accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[684] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.unpersist()\n",
    "cvData.unpersist()\n",
    "testData.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
